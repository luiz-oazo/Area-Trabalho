#!/usr/bin/env python3
"""
PROGRAMA 2: CONSULTA RAG INTELIGENTE
Usa o aprendizado do programa 3 para dar respostas melhores
Otimizado para MacBook
"""

import pickle
import os
import faiss
import numpy as np
import json
from sentence_transformers import SentenceTransformer
from transformers import pipeline
import sys

class SmartRAGQuery:
    def __init__(self, save_dir="./rag_system_mac"):
        self.save_dir = save_dir
        self.embedding_model = None
        self.index = None
        self.chunks = None
        self.metadata = None
        self.generator = None

        # Sistema de memÃ³ria (carregado do programa 3)
        self.document_scores = {}
        self.has_memory = False
        self.total_feedback_queries = 0

    def load_system(self):
        """Carrega o sistema RAG treinado."""
        print("ğŸ”„ Carregando sistema RAG inteligente...")
        print(f"ğŸ“ DiretÃ³rio: {os.path.abspath(self.save_dir)}")

        if not os.path.exists(self.save_dir):
            print(f"âŒ Sistema nÃ£o encontrado em {self.save_dir}")
            print("Execute primeiro: python 1_rag_trainer.py")
            return False

        try:
            # Carrega componentes bÃ¡sicos
            print("  ğŸ“ Carregando modelo de embedding...")
            self.embedding_model = SentenceTransformer(f"{self.save_dir}/embedding_model")

            print("  ğŸ” Carregando Ã­ndice Faiss...")
            self.index = faiss.read_index(f"{self.save_dir}/faiss_index.bin")

            print("  ğŸ“Š Carregando dados...")
            with open(f"{self.save_dir}/rag_data.pkl", "rb") as f:
                data = pickle.load(f)
                self.chunks = data['chunks']
                self.metadata = data['metadata']

            print("  ğŸ¤– Carregando gerador de texto...")
            self.generator = pipeline(
                "text2text-generation",
                model="t5-small",
                max_length=200,
                do_sample=False
            )

            # TENTA CARREGAR MEMÃ“RIA DO PROGRAMA 3
            self.load_feedback_memory()

            print("âœ… Sistema carregado com sucesso!")
            print(f"ğŸ“Š {len(self.chunks)} chunks disponÃ­veis")
            return True

        except Exception as e:
            print(f"âŒ Erro ao carregar sistema: {e}")
            return False

    def load_feedback_memory(self):
        """Carrega memÃ³ria de feedback do programa 3."""
        try:
            memory_file = f"{self.save_dir}/persistent_memory.json"

            if os.path.exists(memory_file):
                print("  ğŸ§  Carregando memÃ³ria de feedback...")
                with open(memory_file, "r", encoding='utf-8') as f:
                    memory_data = json.load(f)

                    self.document_scores = memory_data.get("document_scores", {})
                    query_history = memory_data.get("query_history", [])
                    self.total_feedback_queries = len(query_history)

                    if self.document_scores:
                        self.has_memory = True
                        docs_with_feedback = len(self.document_scores)

                        print(f"  ğŸ‰ MemÃ³ria encontrada!")
                        print(f"     ğŸ“ˆ {self.total_feedback_queries} consultas com feedback")
                        print(f"     ğŸ“š {docs_with_feedback} documentos treinados")

                        # Mostra alguns documentos bem avaliados
                        best_docs = self.get_best_documents(3)
                        if best_docs:
                            print(f"     ğŸ† Melhores documentos:")
                            for doc_id, avg_score in best_docs:
                                title = self.metadata[int(doc_id)]['title']
                                print(f"        - {title}: {avg_score:.1f}/5")

                        print("  âœ… Sistema agora usa inteligÃªncia do programa 3!")
                    else:
                        print("  ğŸ“Š MemÃ³ria vazia - usando busca bÃ¡sica")
            else:
                print("  ğŸ“Š Nenhuma memÃ³ria encontrada - usando busca bÃ¡sica")
                print("  ğŸ’¡ Execute o programa 3 para treinar o sistema!")

        except Exception as e:
            print(f"  âš ï¸ Erro ao carregar memÃ³ria: {e}")
            print("  ğŸ”„ Usando busca bÃ¡sica")

    def get_best_documents(self, n=5):
        """Retorna os N melhores documentos por avaliaÃ§Ã£o."""
        doc_averages = []
        for doc_id, scores in self.document_scores.items():
            if len(scores) >= 1:
                avg_score = sum(scores) / len(scores)
                doc_averages.append((doc_id, avg_score))

        doc_averages.sort(key=lambda x: x[1], reverse=True)
        return doc_averages[:n]

    def calculate_learned_weight(self, chunk_id):
        """Calcula peso baseado no aprendizado do programa 3."""
        if not self.has_memory:
            return 1.0  # Peso neutro se nÃ£o hÃ¡ memÃ³ria

        chunk_str = str(chunk_id)

        if chunk_str in self.document_scores:
            scores = self.document_scores[chunk_str]
            if len(scores) >= 1:
                # Calcula mÃ©dia das avaliaÃ§Ãµes
                avg_score = sum(scores) / len(scores)

                # Converte para peso (1-5 -> 0.3-2.2)
                if avg_score >= 4.5:
                    return 2.2  # Documentos excelentes
                elif avg_score >= 4.0:
                    return 1.9  # Documentos muito bons
                elif avg_score >= 3.5:
                    return 1.5  # Documentos bons
                elif avg_score >= 2.5:
                    return 1.0  # Documentos neutros
                elif avg_score >= 1.5:
                    return 0.7  # Documentos ruins
                else:
                    return 0.3  # Documentos muito ruins

        return 1.0  # Peso neutro para documentos sem feedback

    def smart_search(self, question, k=5):
        """Busca inteligente usando aprendizado do programa 3."""
        try:
            # Cria embedding da pergunta
            question_embedding = self.embedding_model.encode([question])
            question_embedding = np.array(question_embedding).astype('float32')

            # Busca mais documentos para ter opÃ§Ãµes
            search_k = k * 2 if self.has_memory else k
            scores, indices = self.index.search(question_embedding, search_k)

            # Aplica pesos aprendidos (se houver memÃ³ria)
            results = []
            for i, idx in enumerate(indices[0]):
                if idx < len(self.chunks):
                    base_score = float(scores[0][i])

                    if self.has_memory:
                        learned_weight = self.calculate_learned_weight(idx)
                        adjusted_score = base_score / learned_weight  # Menor = melhor

                        # Determina confianÃ§a baseada no aprendizado
                        if learned_weight > 1.8:
                            confidence = "ğŸ”¥"  # Muito confiÃ¡vel
                        elif learned_weight > 1.2:
                            confidence = "ğŸ‘"  # ConfiÃ¡vel
                        elif learned_weight < 0.8:
                            confidence = "âš ï¸"  # Pouco confiÃ¡vel
                        else:
                            confidence = "ğŸ“Š"  # Neutro
                    else:
                        learned_weight = 1.0
                        adjusted_score = base_score
                        confidence = "ğŸ“Š"  # Neutro (sem memÃ³ria)

                    results.append({
                        'text': self.chunks[idx],
                        'metadata': self.metadata[idx],
                        'base_score': base_score,
                        'learned_weight': learned_weight,
                        'adjusted_score': adjusted_score,
                        'confidence': confidence,
                        'rank': i + 1,
                        'chunk_id': idx
                    })

            # Ordena por score ajustado se hÃ¡ memÃ³ria, senÃ£o por score base
            if self.has_memory:
                results.sort(key=lambda x: x['adjusted_score'])
            else:
                results.sort(key=lambda x: x['base_score'])

            return results[:k]

        except Exception as e:
            print(f"âŒ Erro na busca: {e}")
            return []

    def generate_smart_answer(self, question, context_docs):
        """Gera resposta priorizando documentos bem avaliados."""
        try:
            # Se hÃ¡ memÃ³ria, ordena por peso aprendido
            if self.has_memory:
                sorted_docs = sorted(context_docs, key=lambda x: x['learned_weight'], reverse=True)
            else:
                sorted_docs = context_docs

            # Cria contexto com os melhores documentos
            context_parts = []
            for doc in sorted_docs[:3]:  # Usa os 3 melhores
                title = doc['metadata']['title']
                text = doc['text']
                confidence = doc['confidence']
                context_parts.append(f"Fonte {confidence} ({title}): {text}")

            context = "\n\n".join(context_parts)

            # Limita tamanho do contexto
            if len(context) > 1000:
                context = context[:1000] + "..."

            # Cria prompt
            if self.has_memory:
                prompt_prefix = "Com base no contexto verificado e otimizado"
            else:
                prompt_prefix = "Com base no contexto fornecido"

            prompt = f"""{prompt_prefix}, responda a pergunta de forma clara e precisa.

Pergunta: {question}

Contexto:
{context}

Resposta:"""

            # Gera resposta
            response = self.generator(prompt, max_length=150, num_return_sequences=1)

            if response and len(response) > 0:
                answer = response[0]['generated_text']
                # Limpa a resposta
                if "Resposta:" in answer:
                    answer = answer.split("Resposta:")[-1].strip()
                return answer
            else:
                return "NÃ£o consegui gerar uma resposta adequada."

        except Exception as e:
            print(f"âŒ Erro ao gerar resposta: {e}")
            return f"Erro: {str(e)}"

    def query(self, question):
        """Executa uma consulta inteligente."""
        print("\n" + "="*60)
        if self.has_memory:
            print("ğŸ” PROCESSANDO COM INTELIGÃŠNCIA APRENDIDA")
        else:
            print("ğŸ” PROCESSANDO SUA PERGUNTA")
        print("="*60)
        print(f"â“ Pergunta: {question}")

        # Busca documentos (inteligente se hÃ¡ memÃ³ria)
        if self.has_memory:
            print("\nğŸ§  Buscando com inteligÃªncia do programa 3...")
        else:
            print("\nğŸ“š Buscando documentos relevantes...")

        docs = self.smart_search(question, k=5)

        if not docs:
            print("âŒ Nenhum documento relevante encontrado.")
            return "Desculpe, nÃ£o encontrei informaÃ§Ãµes relevantes para sua pergunta."

        # Mostra documentos encontrados
        print(f"\nğŸ“‹ DOCUMENTOS SELECIONADOS:")
        for doc in docs[:3]:
            if self.has_memory:
                print(f"  {doc['rank']}. {doc['metadata']['title']} {doc['confidence']}")
                print(f"     Peso aprendido: {doc['learned_weight']:.2f}")
                print(f"     Score: {doc['base_score']:.3f} â†’ {doc['adjusted_score']:.3f}")
            else:
                print(f"  {doc['rank']}. {doc['metadata']['title']} {doc['confidence']}")
                print(f"     Score: {doc['base_score']:.3f}")
            print(f"     Texto: {doc['text'][:80]}...")
            print()

        # Gera resposta
        if self.has_memory:
            print("ğŸ¤– Gerando resposta otimizada...")
        else:
            print("ğŸ¤– Gerando resposta...")

        answer = self.generate_smart_answer(question, docs)

        return answer

    def interactive_mode(self):
        """Modo interativo inteligente."""
        if self.has_memory:
            print("ğŸš€ CONSULTA RAG INTELIGENTE")
            print("="*50)
            print("ğŸ§  Sistema usando aprendizado do programa 3!")
            print(f"ğŸ“Š Baseado em {self.total_feedback_queries} consultas com feedback")
            print("ğŸ’¡ Respostas otimizadas com base nas suas avaliaÃ§Ãµes")
        else:
            print("ğŸš€ CONSULTA RAG BÃSICA")
            print("="*50)
            print("ğŸ“Š Sistema usando busca por similaridade")
            print("ğŸ’¡ Execute o programa 3 para treinar o sistema!")

        print("âŒ¨ï¸  Digite 'sair' para terminar")
        print("="*50)

        while True:
            try:
                print("\n" + "ğŸ¯" + "="*58)
                question = input("â“ Sua pergunta: ").strip()

                if question.lower() in ['sair', 'exit', 'quit', '']:
                    if self.has_memory:
                        print("\nğŸ§  Obrigado por usar o sistema inteligente!")
                        print("ğŸ’¡ Continue treinando com o programa 3 para melhorar ainda mais!")
                    else:
                        print("\nğŸ‘‹ AtÃ© logo!")
                        print("ğŸ’¡ Execute o programa 3 para treinar o sistema!")
                    break

                if len(question) < 3:
                    print("âš ï¸  Pergunta muito curta. Tente novamente.")
                    continue

                # Processa pergunta
                answer = self.query(question)

                # Mostra resposta
                if self.has_memory:
                    print("\nğŸ¤– RESPOSTA INTELIGENTE:")
                else:
                    print("\nğŸ¤– RESPOSTA:")
                print("-" * 60)
                print(answer)
                print("-" * 60)

                if not self.has_memory:
                    print("\nğŸ’¡ Dica: Execute o programa 3 para treinar o sistema!")
                    print("   Suas avaliaÃ§Ãµes tornarÃ£o as respostas muito melhores!")

            except KeyboardInterrupt:
                print("\n\nâ¹ï¸  Programa interrompido.")
                break
            except Exception as e:
                print(f"\nâŒ Erro: {e}")

def main():
    """FunÃ§Ã£o principal."""
    print("ğŸ RAG QUERY INTELIGENTE PARA MACBOOK")
    print("Usa o aprendizado do programa 3 automaticamente\n")

    try:
        # Inicializa sistema
        rag = SmartRAGQuery()

        # Carrega sistema
        if not rag.load_system():
            print("\nğŸ’¡ Execute primeiro o treinamento:")
            print("   python 1_rag_trainer.py")
            sys.exit(1)

        # Inicia modo interativo
        rag.interactive_mode()

    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  Programa cancelado.")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ Erro inesperado: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
