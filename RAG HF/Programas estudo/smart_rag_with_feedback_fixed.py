import pickle
import os
import faiss
import numpy as np
import json
from sentence_transformers import SentenceTransformer
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
from datetime import datetime
import random

class SmartRAGWithFeedback:
    def __init__(self, save_dir="/content/simple_rag_system"):  # CORRIGIDO: mesmo diret√≥rio do treinador
        self.save_dir = save_dir
        self.embedding_model = None
        self.index = None
        self.dataset = None
        self.generator = None
        self.tokenizer = None
        self.feedback_data = {}
        self.document_scores = {}
        self.query_history = []

    def load_system(self):
        """Carrega o sistema RAG com dados de feedback."""
        try:
            print("üîÑ Carregando sistema RAG inteligente...")

            if not os.path.exists(self.save_dir):
                print(f"‚ùå Diret√≥rio {self.save_dir} n√£o encontrado!")
                print("Execute primeiro o simple_rag_trainer.py para criar o sistema.")
                return False

            # Carregar componentes b√°sicos
            print("  Carregando modelo de embedding...")
            self.embedding_model = SentenceTransformer(f"{self.save_dir}/embedding_model")

            print("  Carregando √≠ndice Faiss...")
            self.index = faiss.read_index(f"{self.save_dir}/faiss_index.bin")

            print("  Carregando dataset...")
            with open(f"{self.save_dir}/dataset.pkl", "rb") as f:
                self.dataset = pickle.load(f)

            # Carregar modelo gerador
            print("  Carregando modelo gerador...")
            try:
                self.tokenizer = AutoTokenizer.from_pretrained("t5-small")
                model = AutoModelForSeq2SeqLM.from_pretrained("t5-small")
                self.generator = pipeline(
                    "text2text-generation",
                    model=model,
                    tokenizer=self.tokenizer,
                    max_length=200,
                    do_sample=False
                )
            except Exception as e:
                print(f"    Usando pipeline padr√£o: {e}")
                self.generator = pipeline("text2text-generation", model="t5-small")

            # Carregar dados de feedback
            self.load_feedback_data()

            print("‚úÖ Sistema carregado com sucesso!")
            return True

        except Exception as e:
            print(f"‚ùå Erro ao carregar sistema: {e}")
            return False

    def load_feedback_data(self):
        """Carrega dados de feedback anteriores."""
        try:
            feedback_file = f"{self.save_dir}/feedback_data.json"
            if os.path.exists(feedback_file):
                with open(feedback_file, "r") as f:
                    data = json.load(f)
                    self.feedback_data = data.get("feedback_data", {})
                    self.document_scores = data.get("document_scores", {})
                    self.query_history = data.get("query_history", [])
                print(f"  üìä Carregados {len(self.feedback_data)} feedbacks anteriores")
            else:
                print("  üìä Nenhum feedback anterior encontrado - come√ßando do zero")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Erro ao carregar feedback: {e}")

    def save_feedback_data(self):
        """Salva dados de feedback."""
        try:
            feedback_file = f"{self.save_dir}/feedback_data.json"
            data = {
                "feedback_data": self.feedback_data,
                "document_scores": self.document_scores,
                "query_history": self.query_history,
                "last_updated": datetime.now().isoformat()
            }
            with open(feedback_file, "w") as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao salvar feedback: {e}")

    def calculate_document_relevance_score(self, doc_id):
        """Calcula pontua√ß√£o de relev√¢ncia de um documento baseada no feedback."""
        if str(doc_id) in self.document_scores:
            scores = self.document_scores[str(doc_id)]
            if scores:
                avg_score = sum(scores) / len(scores)
                # Normalizar para peso entre 0.5 e 2.0
                weight = 0.5 + (avg_score - 1) * 0.375  # (5-1) * 0.375 = 1.5, ent√£o 0.5 + 1.5 = 2.0
                return max(0.5, min(2.0, weight))
        return 1.0  # Peso neutro para documentos sem feedback

    def retrieve_documents_with_learning(self, question, k=5):
        """Recupera documentos considerando feedback anterior."""
        try:
            # Buscar mais documentos inicialmente
            question_embedding = self.embedding_model.encode([question])
            question_embedding = np.array(question_embedding).astype('float32')

            # Buscar top-k*2 para ter mais op√ß√µes
            scores, indices = self.index.search(question_embedding, k*2)

            retrieved_docs = []
            for i, idx in enumerate(indices[0]):
                if idx < len(self.dataset['chunks']) and idx >= 0:
                    chunk = self.dataset['chunks'][idx]
                    metadata = self.dataset['metadata'][idx]

                    # Calcular pontua√ß√£o ajustada pelo feedback
                    base_score = float(scores[0][i])
                    relevance_weight = self.calculate_document_relevance_score(idx)
                    adjusted_score = base_score / relevance_weight  # Menor score = melhor

                    doc = {
                        'title': metadata['title'],
                        'text': chunk,
                        'base_score': base_score,
                        'relevance_weight': relevance_weight,
                        'adjusted_score': adjusted_score,
                        'url': metadata['url'],
                        'chunk_id': idx,
                        'doc_id': idx
                    }
                    retrieved_docs.append(doc)

            # Ordenar por pontua√ß√£o ajustada e pegar os top-k
            retrieved_docs.sort(key=lambda x: x['adjusted_score'])
            return retrieved_docs[:k]

        except Exception as e:
            print(f"‚ùå Erro ao recuperar documentos: {e}")
            return []

    def generate_answer_with_context(self, question, context_docs):
        """Gera resposta melhorada baseada no contexto."""
        try:
            # Priorizar documentos com melhor feedback
            sorted_docs = sorted(context_docs, key=lambda x: x['relevance_weight'], reverse=True)

            # Criar contexto priorizando documentos bem avaliados
            context_parts = []
            for doc in sorted_docs[:3]:  # Usar apenas os 3 melhores
                context_parts.append(f"Fonte ({doc['title']}): {doc['text']}")

            context = "\n\n".join(context_parts)

            # Limitar tamanho do contexto
            max_context_length = 900
            if len(context) > max_context_length:
                context = context[:max_context_length] + "..."

            # Criar prompt melhorado
            prompt = f"""Baseado no contexto fornecido, responda a pergunta de forma clara e precisa.

Pergunta: {question}

Contexto:
{context}

Resposta detalhada:"""

            # Gerar resposta
            response = self.generator(prompt, max_length=150, num_return_sequences=1)

            if response and len(response) > 0:
                answer = response[0]['generated_text']
                # Limpar resposta
                if "Resposta detalhada:" in answer:
                    answer = answer.split("Resposta detalhada:")[-1].strip()
                elif "Resposta:" in answer:
                    answer = answer.split("Resposta:")[-1].strip()
                return answer
            else:
                return "N√£o foi poss√≠vel gerar uma resposta adequada."

        except Exception as e:
            print(f"‚ùå Erro ao gerar resposta: {e}")
            return f"Erro ao processar: {str(e)}"

    def record_feedback(self, question, answer, docs_used, rating):
        """Registra feedback do usu√°rio."""
        try:
            # Criar ID √∫nico para esta consulta
            query_id = f"query_{len(self.query_history)}"

            # Registrar na hist√≥ria
            query_record = {
                "id": query_id,
                "question": question,
                "answer": answer,
                "rating": rating,
                "timestamp": datetime.now().isoformat(),
                "docs_used": [doc['doc_id'] for doc in docs_used]
            }
            self.query_history.append(query_record)

            # Atualizar pontua√ß√µes dos documentos
            for doc in docs_used:
                doc_id = str(doc['doc_id'])
                if doc_id not in self.document_scores:
                    self.document_scores[doc_id] = []
                self.document_scores[doc_id].append(rating)

                # Manter apenas os √∫ltimos 10 feedbacks por documento
                if len(self.document_scores[doc_id]) > 10:
                    self.document_scores[doc_id] = self.document_scores[doc_id][-10:]

            # Salvar dados
            self.save_feedback_data()

            # Mostrar estat√≠sticas
            self.show_learning_stats(rating)

        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao registrar feedback: {e}")

    def show_learning_stats(self, current_rating):
        """Mostra estat√≠sticas de aprendizado."""
        if len(self.query_history) > 1:
            recent_ratings = [q['rating'] for q in self.query_history[-5:]]
            avg_recent = sum(recent_ratings) / len(recent_ratings)

            print(f"\nüìä ESTAT√çSTICAS DE APRENDIZADO:")
            print(f"   Nota atual: {current_rating}/5")
            print(f"   M√©dia das √∫ltimas 5 consultas: {avg_recent:.1f}/5")
            print(f"   Total de consultas: {len(self.query_history)}")
            print(f"   Documentos com feedback: {len(self.document_scores)}")

            if current_rating >= 4:
                print("   üéâ √ìtima resposta! O sistema est√° aprendendo.")
            elif current_rating >= 3:
                print("   üëç Resposta boa. Continuando a melhorar.")
            else:
                print("   üîÑ Resposta ruim. Ajustando para pr√≥ximas consultas.")

    def query_with_feedback(self, question):
        """Executa consulta completa com sistema de feedback."""
        print("\n" + "="*60)
        print("üîç PROCESSANDO SUA PERGUNTA...")
        print("="*60)

        # Recuperar documentos com aprendizado
        print("üìö Buscando documentos relevantes (considerando feedback anterior)...")
        docs = self.retrieve_documents_with_learning(question, k=3)

        if not docs:
            return "‚ùå Nenhum documento relevante encontrado.", []

        # Mostrar documentos encontrados
        print(f"\nüìã DOCUMENTOS SELECIONADOS:")
        for i, doc in enumerate(docs, 1):
            weight_status = "üî•" if doc['relevance_weight'] > 1.2 else "üëç" if doc['relevance_weight'] > 0.8 else "‚ö†Ô∏è"
            print(f"   {i}. {doc['title']} {weight_status}")
            print(f"      Peso de relev√¢ncia: {doc['relevance_weight']:.2f}")
            print(f"      Texto: {doc['text'][:100]}...")
            print()

        # Gerar resposta
        print("ü§ñ Gerando resposta otimizada...")
        answer = self.generate_answer_with_context(question, docs)

        return answer, docs

def main():
    """Fun√ß√£o principal com sistema de feedback."""
    print("üöÄ SISTEMA RAG INTELIGENTE COM FEEDBACK")
    print("="*60)
    print("Este sistema aprende com suas avalia√ß√µes!")
    print("Notas 1-2: Resposta ruim | 3: OK | 4-5: Muito boa")
    print("="*60)

    # Inicializar sistema
    rag = SmartRAGWithFeedback()

    if not rag.load_system():
        print("‚ùå Execute primeiro o simple_rag_trainer.py")
        return

    print("\n‚úÖ Sistema carregado e pronto!")

    while True:
        print("\n" + "üéØ" + "="*58)
        question = input("‚ùì Sua pergunta (ou 'sair' para terminar): ").strip()

        if question.lower() in ['sair', 'exit', 'quit', '']:
            print("\nüìä RESUMO DA SESS√ÉO:")
            if rag.query_history:
                session_ratings = [q['rating'] for q in rag.query_history[-10:]]
                avg_session = sum(session_ratings) / len(session_ratings)
                print(f"   Consultas nesta sess√£o: {len([q for q in rag.query_history if 'session' not in q])}")
                print(f"   Nota m√©dia da sess√£o: {avg_session:.1f}/5")
            print("\nüëã Obrigado por ajudar o sistema a aprender!")
            break

        # Fazer consulta
        answer, docs_used = rag.query_with_feedback(question)

        # Mostrar resposta
        print("\nü§ñ RESPOSTA:")
        print("-" * 60)
        print(answer)
        print("-" * 60)

        # Solicitar feedback
        print("\n‚≠ê AVALIE A RESPOSTA:")
        print("1 = Muito ruim | 2 = Ruim | 3 = OK | 4 = Boa | 5 = Excelente")

        while True:
            try:
                rating = input("Sua nota (1-5): ").strip()
                rating = int(rating)
                if 1 <= rating <= 5:
                    break
                else:
                    print("Por favor, digite um n√∫mero entre 1 e 5.")
            except ValueError:
                print("Por favor, digite um n√∫mero v√°lido.")

        # Registrar feedback
        rag.record_feedback(question, answer, docs_used, rating)

        # Feedback para o usu√°rio
        if rating < 3:
            print("\nüîÑ Obrigado! Vou ajustar para melhorar as pr√≥ximas respostas.")
        elif rating == 3:
            print("\nüëç Obrigado! Continuarei trabalhando para melhorar.")
        else:
            print("\nüéâ √ìtimo! Estou aprendendo com seu feedback positivo.")

if __name__ == "__main__":
    main()
