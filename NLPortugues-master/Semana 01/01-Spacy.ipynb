{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_ELGedbTEvV"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/imagens/logo_nlportugues.png\"   width=\"150\" align=\"right\">\n",
    "\n",
    "\n",
    "\n",
    "# Lista 1 - spaCy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8y9-tiGa321"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "387KBr8bTEvY"
   },
   "source": [
    "O [spaCy](\"https://spacy.io\") é uma bilbioteca Python de código fonte [aberto](\"https://github.com/explosion/spaCy\") para Processamento de \n",
    "Linguagem Natural, constantemente atualizada e mantida. Essa biblioteca é capaz de \n",
    "processar diversas línguas, inclusive o português.\n",
    "\n",
    "### Instalação\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8z9R44NUThZb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Using cached murmurhash-1.0.10-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Using cached cymem-2.0.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Using cached preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy)\n",
      "  Downloading thinc-8.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Using cached srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (72.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (24.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.4.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Downloading blis-1.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Downloading numpy-2.0.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Downloading spacy-3.8.2-cp311-cp311-macosx_11_0_arm64.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.8-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
      "Downloading langcodes-3.4.1-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached murmurhash-1.0.10-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
      "Using cached preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl (128 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl (488 kB)\n",
      "Downloading thinc-8.3.2-cp311-cp311-macosx_11_0_arm64.whl (774 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.2/774.2 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp311-cp311-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.0.1-cp311-cp311-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (174 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.0/175.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, shellingham, numpy, murmurhash, marisa-trie, cloudpathlib, catalogue, srsly, preshed, language-data, blis, typer, langcodes, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "scipy 1.11.4 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.0.2 which is incompatible.\n",
      "streamlit 1.30.0 requires numpy<2,>=1.19.3, but you have numpy 2.0.2 which is incompatible.\n",
      "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.1 which is incompatible.\n",
      "pandas 2.1.4 requires numpy<2,>=1.23.2; python_version == \"3.11\", but you have numpy 2.0.2 which is incompatible.\n",
      "tensorflow-macos 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.5.0 which is incompatible.\n",
      "tensorflow-macos 2.15.0 requires ml-dtypes~=0.2.0, but you have ml-dtypes 0.4.0 which is incompatible.\n",
      "tensorflow-macos 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 2.0.2 which is incompatible.\n",
      "tensorflow-macos 2.15.0 requires tensorboard<2.16,>=2.15, but you have tensorboard 2.17.1 which is incompatible.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
      "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.0.2 which is incompatible.\n",
      "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.2 which is incompatible.\n",
      "astropy 5.3.4 requires numpy<2,>=1.21, but you have numpy 2.0.2 which is incompatible.\n",
      "numba 0.59.0 requires numpy<1.27,>=1.22, but you have numpy 2.0.2 which is incompatible.\n",
      "pywavelets 1.5.0 requires numpy<2.0,>=1.22.4, but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed blis-1.0.1 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.8 langcodes-3.4.1 language-data-1.2.0 marisa-trie-1.2.1 murmurhash-1.0.10 numpy-2.0.2 preshed-3.0.9 shellingham-1.5.4 spacy-3.8.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.3.2 typer-0.12.5 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnieqpc7TEva"
   },
   "source": [
    "Após instalar o pacote spaCy devemos baixar as ferramentas específicas para o português  com o seguinte comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "U2xrX5-cqK6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "\r\n",
      "\u001b[31mAborted.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iv8ivfCnTEvd"
   },
   "source": [
    "Uma vez que temos o pacote instalado e os módulos para português baixado,  podemos começar a utilizar  o spaCy, importando o pacote e carregando o módulo para português.\n",
    "\n",
    "**Nota:** Caso seus resultados sejam diferentes dos descritos neste texto isso provavelmente significa que você está utilizando uma versão diferente do spaCy, como essa ferramenta é atualizada com frequência não é incomum encontrar discrepâncias nos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7pr5NflhTEve"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpt_core_news_sm\u001b[39;00m\n\u001b[1;32m      3\u001b[0m spacyPT \u001b[38;5;241m=\u001b[39m pt_core_news_sm\u001b[38;5;241m.\u001b[39mload()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pt_core_news_sm\n",
    "spacyPT = pt_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1652775744584,
     "user": {
      "displayName": "Alan Barzilay",
      "userId": "11025662713341670302"
     },
     "user_tz": -120
    },
    "id": "WUa8_JVmTEvf",
    "outputId": "e381270a-8706-4e3f-da1f-9a2c652de5c6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'3.3.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCgdvPK1TEvg"
   },
   "source": [
    "É importante notar que o spaCy assume que os caracteres estão codificados no formato utf-8.  O primeiro passo portanto é gerar uma entrada nesse formato e submetê-la ao módulo carregado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1652775744584,
     "user": {
      "displayName": "Alan Barzilay",
      "userId": "11025662713341670302"
     },
     "user_tz": -120
    },
    "id": "_o7Q9inqTEvh",
    "outputId": "3f2fe985-82e5-42c1-f475-50a1edab4f76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mais vale um asno que me carregue que um cavalo que me derrube."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrada = spacyPT(\"Mais vale um asno que me carregue que um cavalo que me derrube.\")\n",
    "entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhoKGbccTEvi"
   },
   "source": [
    "### Tokenização (itemização)\n",
    "\n",
    "A entrada que acabamos de gerar é uma sequência iterável de tokens (itens,  \n",
    "ou instâncias de palavras). Se quisermos verificar qual o texto contido nessa \n",
    "sequência iterável,  usamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1652775744585,
     "user": {
      "displayName": "Alan Barzilay",
      "userId": "11025662713341670302"
     },
     "user_tz": -120
    },
    "id": "HZFtnbHUTEvj",
    "outputId": "06d6e3f9-35eb-4e84-a280-03d170bf932b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Mais vale um asno que me carregue que um cavalo que me derrube.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrada.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5_1tofrTEvk"
   },
   "source": [
    "Se quisermos dividir a entrada em token,  podemos utilizar o método __split__: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1652775744585,
     "user": {
      "displayName": "Alan Barzilay",
      "userId": "11025662713341670302"
     },
     "user_tz": -120
    },
    "id": "nG2rMfWYTEvm",
    "outputId": "b665f13a-6cc9-4c31-ce92-c5861c86bd14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mais',\n",
       " 'vale',\n",
       " 'um',\n",
       " 'asno',\n",
       " 'que',\n",
       " 'me',\n",
       " 'carregue',\n",
       " 'que',\n",
       " 'um',\n",
       " 'cavalo',\n",
       " 'que',\n",
       " 'me',\n",
       " 'derrube.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrada.text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSpMSZrzTEvm"
   },
   "source": [
    "Note que o ponto  final foi absorvido pela palavra;  o mesmo teria acontecido com \n",
    "outros sinais de pontuação a utilizar  o método __split__. Para separar a pontuação \n",
    "das palavras utilizamos a  tokenização implícita realizada pelo comando __in__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1652775744586,
     "user": {
      "displayName": "Alan Barzilay",
      "userId": "11025662713341670302"
     },
     "user_tz": -120
    },
    "id": "CyjtxYEMTEvm",
    "outputId": "d0a5e9cc-752e-4027-ae83-cbb69cb6c97e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Mais, vale, um, asno, que, me, carregue, que, um, cavalo, que, me, derrube, .]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in entrada]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9Fy34xoTEvn"
   },
   "source": [
    "Note que os streams não estão entre aspas,  pois na realidade esta lista contém uma sequência de objetos da classe __Token__. \n",
    "\n",
    "Se o objetivo é obter uma lista de Strings,  podemos proceder da seguinte maneira.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1652775744586,
     "user": {
      "displayName": "Alan Barzilay",
      "userId": "11025662713341670302"
     },
     "user_tz": -120
    },
    "id": "I5I-X9vJTEvn",
    "outputId": "27340968-cb82-4d4d-9cc4-b380e2500491"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mais',\n",
       " 'vale',\n",
       " 'um',\n",
       " 'asno',\n",
       " 'que',\n",
       " 'me',\n",
       " 'carregue',\n",
       " 'que',\n",
       " 'um',\n",
       " 'cavalo',\n",
       " 'que',\n",
       " 'me',\n",
       " 'derrube',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in entrada]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EC2dnbRTEvp"
   },
   "source": [
    "E para eliminar totalmente a pontuação da lista,  é só restringirr  a sua criação usando __is_punct__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1652776211462,
     "user": {
      "displayName": "Alan Barzilay",
      "userId": "11025662713341670302"
     },
     "user_tz": -120
    },
    "id": "UkTxxfstTEvp",
    "outputId": "23999482-3d9c-4137-f182-2280efb668d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mais',\n",
       " 'vale',\n",
       " 'um',\n",
       " 'asno',\n",
       " 'que',\n",
       " 'me',\n",
       " 'carregue',\n",
       " 'que',\n",
       " 'um',\n",
       " 'cavalo',\n",
       " 'que',\n",
       " 'me',\n",
       " 'derrube']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in entrada if not token.is_punct]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJHmrb02TEvp"
   },
   "source": [
    "O spaCy já vem treinado para realizar etiquetagem morfossintática (PoS tagging),  o que pode ser mostrado da seguinte maneira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1652776213008,
     "user": {
      "displayName": "Alan Barzilay",
      "userId": "11025662713341670302"
     },
     "user_tz": -120
    },
    "id": "UfxFqqCbTEvq",
    "outputId": "9b03e90e-56fd-4039-8b06-470aa97b3e41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mais', 'ADV'),\n",
       " ('vale', 'VERB'),\n",
       " ('um', 'DET'),\n",
       " ('asno', 'NOUN'),\n",
       " ('que', 'PRON'),\n",
       " ('me', 'PRON'),\n",
       " ('carregue', 'VERB'),\n",
       " ('que', 'SCONJ'),\n",
       " ('um', 'DET'),\n",
       " ('cavalo', 'NOUN'),\n",
       " ('que', 'PRON'),\n",
       " ('me', 'PRON'),\n",
       " ('derrube', 'VERB'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.text, token.pos_) for token in entrada]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icqdYydXTEvq"
   },
   "source": [
    "A assistência do etiquetador nos permite fazer buscas bastante sofisticadas. Por exemplo podemos buscar os lemas de todos os verbos encontrados  na sentença."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1652776217602,
     "user": {
      "displayName": "Alan Barzilay",
      "userId": "11025662713341670302"
     },
     "user_tz": -120
    },
    "id": "gAUS7nCCTEvr",
    "outputId": "1d560ea4-2aaf-4d9c-dd7f-ac594d335289"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valer', 'carregar', 'derrube']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.lemma_ for token in entrada if token.pos_ == 'VERB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6Mjy3wMTEvr"
   },
   "source": [
    "Os lemas de verbos conjugados nos fornecem  a sua forma infinitiva. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0bum0sCTEvs"
   },
   "source": [
    "### Reconhecimento de entidades nomeadas\n",
    "\n",
    "A biblioteca já vem treinada com um  mecanismo que permite o reconhecimento de \n",
    "entidades nomeadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1652775892523,
     "user": {
      "displayName": "Alan Barzilay",
      "userId": "11025662713341670302"
     },
     "user_tz": -120
    },
    "id": "VFmJt1pYTEvs",
    "outputId": "bc9bd6f9-6fb8-4585-f1d0-bfdb9d5bc3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CBF, Comitê de Apelações da FIFA, Neymar, Copa América, Conmebol)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(CBF, 'ORG'),\n",
       " (Comitê de Apelações da FIFA, 'ORG'),\n",
       " (Neymar, 'PER'),\n",
       " (Copa América, 'MISC'),\n",
       " (Conmebol, 'ORG')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto2 = spacyPT(\"A CBF fez um pedido de análise ao Comitê de Apelações da FIFA a fim de diminuir a pena do atacante Neymar, suspenso da Copa América pela Conmebol.\")\n",
    "print(texto2.ents)\n",
    "[(entidade,entidade.label_) for entidade in texto2.ents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugIP-xrPTEvt"
   },
   "source": [
    "___________________________\n",
    "# <font color='blue'>  Questão 1 </font>\n",
    "\n",
    "Utilizando o spacy, extraia o nome dos personagens presentes no terceiro capitulo da obra \"Mémorias postumas de Brás Cubas\" de Machado de Assis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuRJF6YcTEvt",
    "outputId": "1dcc310c-d751-4053-f0d7-8603274e49d1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mas, já que falei nos meus dois tios, deixem-me fazer aqui um curto esboço genealógico.        O fundador de minha família foi um certo Damião Cubas, que floresceu na primeira metade do século XVIII. Era tanoeiro de ofício, natural do Rio de Janeiro, onde teria morrido na penúria e na obscuridade, se somente exercesse a tanoaria. Mas não; fez-se lavrador, plantou, colheu, permutou o seu produto por boas e honradas patacas, até que morreu, deixando grosso cabedal a um filho, o licenciado Luís Cubas. Neste rapaz é que verdadeiramente começa a série de meus avós -- dos avós que a minha família sempre confessou -  porque o Damião Cubas era afinal de contas um tanoeiro, e talvez mau tanoeiro, ao passo que o Luís Cubas estudou em Coimbra, primou no Estado, e foi um dos amigos particulares do vice-rei conde da Cunha.        Como este apelido de Cubas lhe cheirasse excessivamente a tanoaria, alegava meu pai, bisneto do Damião, que o dito apelido fora dado a um cavaleiro, herói nas jornadas da Africa, em prêmio da façanha que praticou arrebatando trezentas cubas ao mouros. Meu pai era homem de imaginação; escapou à tanoaria nas asas de um calembour. Era um bom caráter, meu pai, varão digno e leal como poucos. Tinha, é verdade, uns fumos de pacholice; mas quem não é um pouco pachola nesse mundo? Releva notar que ele não recorreu à inventiva senão depois de experimentar a falsificação; primeiramente, entroncou-se na família daquele meu famoso homônimo, o capitão-mor Brás Cubas, que fundou a vila de São Vicente, onde morreu em 1592, e por esse motivo é que me deu o nome de Brás. Opôs-se-lhe, porém, a família do capitão-mor, e foi então que ele imaginou as trezentas cubas mouriscas.        Vivem ainda alguns membros de minha família, minha sobrinha Venância, por exemplo, o lírio-do-vale, que é a flor das damas do seu tempo; vive o pai, o Cotrim, um sujeito que... Mas não antecipemos os sucessos; acabemos de uma vez com o nosso emplasto. '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_3_bras_cubas = \"Mas, já que falei nos meus dois tios, deixem-me fazer aqui um curto esboço genealógico.        O fundador de minha família foi um certo Damião Cubas, que floresceu na primeira metade do século XVIII. Era tanoeiro de ofício, natural do Rio de Janeiro, onde teria morrido na penúria e na obscuridade, se somente exercesse a tanoaria. Mas não; fez-se lavrador, plantou, colheu, permutou o seu produto por boas e honradas patacas, até que morreu, deixando grosso cabedal a um filho, o licenciado Luís Cubas. Neste rapaz é que verdadeiramente começa a série de meus avós -- dos avós que a minha família sempre confessou -  porque o Damião Cubas era afinal de contas um tanoeiro, e talvez mau tanoeiro, ao passo que o Luís Cubas estudou em Coimbra, primou no Estado, e foi um dos amigos particulares do vice-rei conde da Cunha.        Como este apelido de Cubas lhe cheirasse excessivamente a tanoaria, alegava meu pai, bisneto do Damião, que o dito apelido fora dado a um cavaleiro, herói nas jornadas da Africa, em prêmio da façanha que praticou arrebatando trezentas cubas ao mouros. Meu pai era homem de imaginação; escapou à tanoaria nas asas de um calembour. Era um bom caráter, meu pai, varão digno e leal como poucos. Tinha, é verdade, uns fumos de pacholice; mas quem não é um pouco pachola nesse mundo? Releva notar que ele não recorreu à inventiva senão depois de experimentar a falsificação; primeiramente, entroncou-se na família daquele meu famoso homônimo, o capitão-mor Brás Cubas, que fundou a vila de São Vicente, onde morreu em 1592, e por esse motivo é que me deu o nome de Brás. Opôs-se-lhe, porém, a família do capitão-mor, e foi então que ele imaginou as trezentas cubas mouriscas.        Vivem ainda alguns membros de minha família, minha sobrinha Venância, por exemplo, o lírio-do-vale, que é a flor das damas do seu tempo; vive o pai, o Cotrim, um sujeito que... Mas não antecipemos os sucessos; acabemos de uma vez com o nosso emplasto. \"\n",
    "cap_3_bras_cubas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CG6FJniETEvu"
   },
   "outputs": [],
   "source": [
    "#Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujmz8q2jTEvv"
   },
   "source": [
    "Quais destas repostas estão corretas?  Quais personagens estão faltando?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AxVwxhJTEvv"
   },
   "source": [
    "**<font color='red'> Sua resposta aqui </font>**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3juZmY0jTEvx"
   },
   "source": [
    "# <font color='blue'>  Questão 2 </font>\n",
    "\n",
    "Extraia todos os pronomes deste capitulo.\n",
    "\n",
    "_____________\n",
    "**<font color='red'> Sua resposta aqui </font>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrMsM33ZTEvw"
   },
   "outputs": [],
   "source": [
    "#Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bW_x8XHTEvx"
   },
   "source": [
    "# <font color='blue'>  Questão 3 </font>\n",
    "Utilize os visualizadores para explorar o mapa de dependencias de uma frase a sua escolha deste capitulo.\n",
    "https://spacy.io/usage/visualizers\n",
    "\n",
    "Você pode acessar diretamente uma frase especifica ao utilizar o gerador \"sents\", por exemplo:\n",
    "\n",
    "```python\n",
    "frases = [frase for frase in texto.sents]\n",
    "frases[2]\n",
    "\n",
    "\n",
    "Era tanoeiro de ofício, natural do Rio de Janeiro LOC , onde teria morrido na penúria e na obscuridade, se somente exercesse a tanoaria. \n",
    "```\n",
    "\n",
    "\n",
    "_______________\n",
    "\n",
    "\n",
    "**<font color='red'> Sua resposta aqui </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqUiCknrTEvy"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AWMKGioTEvy"
   },
   "outputs": [],
   "source": [
    "#Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmCGp6yNTEvz"
   },
   "source": [
    "# Fontes \n",
    "Tanto o capitulo utilizado nesta aula quanto a obra completa fazem parte do dominio publico e podem ser encontrados em http://www.dominiopublico.gov.br/download/texto/bv000215.pdf"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of 01-Spacy.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/alan-barzilay/NLPortugues/blob/coursera/Semana%2001/01-Spacy.ipynb",
     "timestamp": 1652726399961
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
